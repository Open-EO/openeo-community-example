{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "connection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be required to import onnxruntime in the UDF.\n",
    "dependencies_url = \"https://artifactory.vgt.vito.be:443/auxdata-public/openeo/onnx_dependencies_1.16.3.zip\"\n",
    "# You can upload your own model to a public download link and paste the url here. An example of a public storage is github, or you can set up a public S3 bucket.\n",
    "model_url = \"https://artifactory.vgt.vito.be:443/auxdata-public/openeo/test_onnx_model.zip\"\n",
    "\n",
    "spatial_extent = {\"west\": 8.908, \"south\": 53.791, \"east\": 8.96, \"north\": 54.016}\n",
    "temporal_extent = [\"2022-10-01\", \"2022-12-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_cube = connection.load_collection(\n",
    "    \"SENTINEL2_L2A\",\n",
    "    temporal_extent=temporal_extent,\n",
    "    spatial_extent=spatial_extent,\n",
    "    bands=[\"B04\"],\n",
    "    max_cloud_cover=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-240612433033446b91231bcbf0cc8099': send 'start'\n",
      "0:00:39 Job 'j-240612433033446b91231bcbf0cc8099': running (progress N/A)\n",
      "0:00:45 Job 'j-240612433033446b91231bcbf0cc8099': running (progress N/A)\n",
      "0:00:51 Job 'j-240612433033446b91231bcbf0cc8099': running (progress N/A)\n",
      "0:01:00 Job 'j-240612433033446b91231bcbf0cc8099': running (progress N/A)\n",
      "0:01:28 Job 'j-240612433033446b91231bcbf0cc8099': Connection error while polling job status: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "0:01:59 Job 'j-240612433033446b91231bcbf0cc8099': running (progress N/A)\n",
      "0:02:12 Job 'j-240612433033446b91231bcbf0cc8099': running (progress N/A)\n",
      "0:02:29 Job 'j-240612433033446b91231bcbf0cc8099': running (progress N/A)\n",
      "0:02:49 Job 'j-240612433033446b91231bcbf0cc8099': running (progress N/A)\n",
      "0:03:13 Job 'j-240612433033446b91231bcbf0cc8099': running (progress N/A)\n",
      "0:03:45 Job 'j-240612433033446b91231bcbf0cc8099': error (progress N/A)\n",
      "Your batch job 'j-240612433033446b91231bcbf0cc8099' failed. Error logs:\n",
      "[{'id': '[1718199225805, 280332]', 'time': '2024-06-12T13:33:45.805Z', 'level': 'error', 'message': 'Task 2 in stage 18.0 failed 4 times; aborting job'}, {'id': '[1718199228443, 28087]', 'time': '2024-06-12T13:33:48.443Z', 'level': 'error', 'message': 'OpenEO batch job failed: UDF exception while evaluating processing graph. Please check your user defined functions.   File \"/opt/openeo/lib/python3.8/site-packages/openeo/udf/run_code.py\", line 196, in run_udf_code\\n    result_cube: xarray.DataArray = func(cube=data.get_datacube_list()[0].get_array(), context=data.user_context)\\n  File \"<string>\", line 59, in apply_datacube\\n  File \"<__array_function__ internals>\", line 179, in apply_over_axes\\nTypeError: _apply_over_axes_dispatcher() got an unexpected keyword argument \\'arr\\''}]\n",
      "Full logs can be inspected in an openEO (web) editor or with `connection.job('j-240612433033446b91231bcbf0cc8099').logs()`.\n"
     ]
    },
    {
     "ename": "JobFailedException",
     "evalue": "Batch job 'j-240612433033446b91231bcbf0cc8099' didn't finish successfully. Status: error (after 0:03:48).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJobFailedException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# We pass the model and dependencies as zip files to the UDF through the job options.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# The zip files provided in this list will be extracted in the UDF environment in a folder indicated by the name after the # symbol.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m job_options \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mudf-dependency-archives\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdependencies_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m#onnx_deps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m#onnx_models\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m     ],\n\u001b[0;32m     27\u001b[0m }\n\u001b[1;32m---> 28\u001b[0m \u001b[43monnx_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput.nc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\VERHAERV\\AppData\\Local\\miniconda3\\envs\\openeobasic\\Lib\\site-packages\\openeo\\rest\\datacube.py:2227\u001b[0m, in \u001b[0;36mDataCube.execute_batch\u001b[1;34m(self, outputfile, out_format, print, max_poll_interval, connection_retry_interval, job_options, validate, **format_options)\u001b[0m\n\u001b[0;32m   2224\u001b[0m     out_format \u001b[38;5;241m=\u001b[39m guess_format(outputfile)\n\u001b[0;32m   2226\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_job(out_format\u001b[38;5;241m=\u001b[39mout_format, job_options\u001b[38;5;241m=\u001b[39mjob_options, validate\u001b[38;5;241m=\u001b[39mvalidate, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_options)\n\u001b[1;32m-> 2227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_synchronous\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2228\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2229\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_poll_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_poll_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_retry_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_retry_interval\u001b[49m\n\u001b[0;32m   2230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\VERHAERV\\AppData\\Local\\miniconda3\\envs\\openeobasic\\Lib\\site-packages\\openeo\\rest\\job.py:239\u001b[0m, in \u001b[0;36mBatchJob.run_synchronous\u001b[1;34m(self, outputfile, print, max_poll_interval, connection_retry_interval)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_synchronous\u001b[39m(\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28mself\u001b[39m, outputfile: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;28mprint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mprint\u001b[39m, max_poll_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, connection_retry_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n\u001b[0;32m    237\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchJob:\n\u001b[0;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Start the job, wait for it to finish and download result\"\"\"\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_and_wait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_poll_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_poll_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_retry_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_retry_interval\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m# TODO #135 support multi file result sets too?\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outputfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\VERHAERV\\AppData\\Local\\miniconda3\\envs\\openeobasic\\Lib\\site-packages\\openeo\\rest\\job.py:321\u001b[0m, in \u001b[0;36mBatchJob.start_and_wait\u001b[1;34m(self, print, max_poll_interval, connection_retry_interval, soft_error_max)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogs(level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mERROR))\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull logs can be inspected in an openEO (web) editor or with `connection.job(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m).logs()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m     )\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JobFailedException(\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt finish successfully. Status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    323\u001b[0m         job\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mJobFailedException\u001b[0m: Batch job 'j-240612433033446b91231bcbf0cc8099' didn't finish successfully. Status: error (after 0:03:48)."
     ]
    }
   ],
   "source": [
    "# Load the UDF from a file.\n",
    "udf = openeo.UDF.from_file(\n",
    "    \"onnx_udf.py\",\n",
    "    context=None, # you can pass extra arguments to the UDF here\n",
    ")\n",
    "\n",
    "# Apply the UDF to the data cube.\n",
    "onnx_result = s2_cube.apply_neighborhood(\n",
    "    udf,\n",
    "    size=[\n",
    "        {\"dimension\": \"x\", \"value\": 256, \"unit\": \"px\"},\n",
    "        {\"dimension\": \"y\", \"value\": 256, \"unit\": \"px\"},\n",
    "    ],\n",
    "    overlap=[\n",
    "        {\"dimension\": \"x\", \"value\": 0, \"unit\": \"px\"},\n",
    "        {\"dimension\": \"y\", \"value\": 0, \"unit\": \"px\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# We pass the model and dependencies as zip files to the UDF through the job options.\n",
    "# The zip files provided in this list will be extracted in the UDF environment in a folder indicated by the name after the # symbol.\n",
    "job_options = {\n",
    "    \"udf-dependency-archives\": [\n",
    "        f\"{dependencies_url}#onnx_deps\",\n",
    "        f\"{model_url}#onnx_models\",\n",
    "    ],\n",
    "}\n",
    "onnx_result.execute_batch(\"output.nc\", job_options=job_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openeobasic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
